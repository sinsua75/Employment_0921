import os
import io
import time
import datetime
from typing import Optional, Dict, Any
import json

import streamlit as st
import pandas as pd
import numpy as np
import requests
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from streamlit_lottie import st_lottie
import openpyxl  # Ensure this library is installed for Excel file handling

# ==============================================================================
# 0. CONFIGURATION & INITIAL SETUP
# ==============================================================================
st.set_page_config(
    page_title="ê¸°í›„ ìœ„ê¸°ëŠ” í™˜ê²½ì„ ë„˜ì–´ ì·¨ì—…ê¹Œì§€ í”ë“ ë‹¤",
    page_icon="ğŸŒ",
    layout="wide"
)

# --- App constants & Data URLs ---
TODAY = datetime.datetime.now().date()
CONFIG = {
    "nasa_gistemp_url": "https://data.giss.nasa.gov/gistemp/tabledata_v4/GLB.Ts+dSST.csv",
    "worldbank_api_url": "https://api.worldbank.org/v2/country/all/indicator/SL.IND.EMPL.ZS",
    "noaa_co2_url": "https://gml.noaa.gov/webdata/ccgg/trends/co2/co2_mm_mlo.txt",
    "font_path": "/fonts/Pretendard-Bold.ttf", # Note: Local font path might need to be adjusted
}
MEMO_FILE = "memos.json"

# ==============================================================================
# 1. UTILITY & DATA LOADING FUNCTIONS
# ==============================================================================
def retry_get(url: str, params: Optional[Dict] = None, **kwargs: Any) -> Optional[requests.Response]:
    """Robust GET request with retries and user-agent."""
    final_headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}
    for attempt in range(kwargs.get('max_retries', 2) + 1):
        try:
            resp = requests.get(url, params=params, headers=final_headers, timeout=kwargs.get('timeout', 15))
            resp.raise_for_status()
            return resp
        except requests.exceptions.RequestException as e:
            if attempt < kwargs.get('max_retries', 2):
                time.sleep(kwargs.get('backoff', 1.0) * (attempt + 1))
                continue
            st.sidebar.warning(f"API ìš”ì²­ ì‹¤íŒ¨: {url.split('?')[0]} ({e})")
            return None

@st.cache_data(ttl=3600)
def preprocess_dataframe(df: pd.DataFrame) -> pd.DataFrame:
    """Standardize and preprocess a dataframe."""
    if df is None or df.empty: return pd.DataFrame()
    d = df.copy()
    d['date'] = pd.to_datetime(d['date'], errors='coerce')
    d = d.dropna(subset=['date'])
    d = d[d['date'].dt.date <= TODAY]
    d['value'] = pd.to_numeric(d['value'], errors='coerce')
    subset_cols = ['date', 'group'] if 'group' in d.columns else ['date']
    d = d.drop_duplicates(subset=subset_cols)
    sort_cols = ['group', 'date'] if 'group' in d.columns else ['date']
    d = d.sort_values(sort_cols).reset_index(drop=True)
    if 'group' in d.columns:
        d['value'] = d.groupby('group')['value'].transform(lambda s: s.interpolate(method='linear', limit_direction='both', limit_area='inside'))
    else:
        d['value'] = d['value'].interpolate(method='linear', limit_direction='both', limit_area='inside')
    return d.dropna(subset=['value']).reset_index(drop=True)

def normalize_series(s: pd.Series) -> pd.Series:
    """Normalize a pandas Series to a 0-1 scale."""
    if s.max() == s.min(): return pd.Series(0.5, index=s.index)
    return (s - s.min()) / (s.max() - s.min())

@st.cache_data(ttl=3600)
def fetch_gistemp_csv() -> Optional[pd.DataFrame]:
    """Fetch and parse NASA GISTEMP global monthly anomalies."""
    resp = retry_get(CONFIG["nasa_gistemp_url"], max_retries=1)
    if resp is None: return None
    try:
        content = resp.content.decode('utf-8', errors='replace')
        lines = content.split('\n')
        data_start_index = next((i for i, line in enumerate(lines) if line.strip().startswith('Year,')), -1)
        if data_start_index == -1: return None
        df = pd.read_csv(io.StringIO("\n".join(lines[data_start_index:])))
        df.columns = [c.strip() for c in df.columns]
        months = ['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']
        present_months = [m for m in months if m in df.columns]
        df_long = df.melt(id_vars=['Year'], value_vars=present_months, var_name='Month', value_name='Anomaly')
        month_map = {name: num for num, name in enumerate(months, 1)}
        df_long['date'] = pd.to_datetime(df_long['Year'].astype(str) + '-' + df_long['Month'].map(month_map).astype(str), errors='coerce')
        df_final = df_long[['date']].copy()
        df_final['value'] = pd.to_numeric(df_long['Anomaly'], errors='coerce')
        df_final['group'] = 'ì§€êµ¬ í‰ê·  ì˜¨ë„ ì´ìƒì¹˜(â„ƒ)'
        return df_final.dropna(subset=['date', 'value'])
    except Exception as e:
        st.sidebar.error(f"GISTEMP ë°ì´í„° íŒŒì‹± ì¤‘ ì˜¤ë¥˜: {e}")
        return None

@st.cache_data(ttl=3600)
def fetch_noaa_co2_data() -> Optional[pd.DataFrame]:
    """Fetch and parse NOAA Mauna Loa CO2 data."""
    resp = retry_get(CONFIG["noaa_co2_url"], max_retries=1)
    if resp is None: return None
    try:
        content = resp.content.decode('utf-8')
        lines = [line for line in content.split('\n') if not line.strip().startswith('#')]
        df = pd.read_csv(io.StringIO('\n'.join(lines)), delim_whitespace=True, header=None,
                         names=['year', 'month', 'decimal_date', 'value', 'value_deseasonalized', 'num_days', 'stdev', 'unc'])
        df['date'] = pd.to_datetime(df[['year', 'month']].assign(day=1))
        df_final = df[['date', 'value']].copy()
        df_final['group'] = 'ëŒ€ê¸° ì¤‘ COâ‚‚ ë†ë„ (ppm)'
        return df_final[df_final['value'] > 0].reset_index(drop=True)
    except Exception as e:
        st.sidebar.error(f"NOAA CO2 ë°ì´í„° íŒŒì‹± ì¤‘ ì˜¤ë¥˜: {e}")
        return None

@st.cache_data(ttl=3600)
def fetch_worldbank_employment() -> Optional[pd.DataFrame]:
    """Fetch World Bank API for Employment in industry, including ISO codes."""
    params = {'format': 'json', 'per_page': '20000'}
    resp = retry_get(CONFIG["worldbank_api_url"], params=params, max_retries=1)
    if resp is None: return None
    try:
        data = resp.json()
        if not isinstance(data, list) or len(data) < 2 or not data[1]: return None
        df = pd.json_normalize(data[1])
        df = df[['country.value', 'countryiso3code', 'date', 'value']]
        df.columns = ['group', 'iso_code', 'year', 'value']
        df['date'] = pd.to_datetime(df['year'] + '-01-01', errors='coerce')
        return df[['date', 'group', 'iso_code', 'value']].dropna()
    except Exception as e:
        st.sidebar.error(f"World Bank ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        return None

def get_sample_climate_data() -> pd.DataFrame:
    """Generate sample climate data as a fallback."""
    dates = pd.date_range(end=TODAY, periods=14*12, freq='MS')
    values = np.round(np.linspace(0.4, 1.2, len(dates)) + np.random.normal(0, 0.05, len(dates)), 3)
    return pd.DataFrame({'date': dates, 'value': values, 'group': 'ì§€êµ¬ í‰ê·  ì˜¨ë„ ì´ìƒì¹˜(â„ƒ)'})

def get_sample_co2_data() -> pd.DataFrame:
    """Generate sample CO2 data as a fallback."""
    dates = pd.date_range(end=TODAY, periods=14*12, freq='MS')
    values = np.round(np.linspace(380, 420, len(dates)) + np.random.normal(0, 0.5, len(dates)), 2)
    return pd.DataFrame({'date': dates, 'value': values, 'group': 'ëŒ€ê¸° ì¤‘ COâ‚‚ ë†ë„ (ppm)'})

def get_sample_employment_data() -> pd.DataFrame:
    """Generate sample employment data as a fallback."""
    years = pd.date_range(start=f"{TODAY.year-9}-01-01", end=f"{TODAY.year}-01-01", freq='AS')
    data = []
    countries = {'í•œêµ­(ì˜ˆì‹œ)': 'KOR', 'OECD í‰ê· (ì˜ˆì‹œ)': 'OED'}
    for country, code in countries.items():
        base_value = 24.0 if 'í•œêµ­' in country else 22.0
        for year in years:
            data.append({'date': year, 'group': country, 'iso_code': code, 'value': float(base_value + np.random.normal(0, 0.8))})
    return pd.DataFrame(data)

@st.cache_data
def get_sample_renewable_data() -> pd.DataFrame:
    """Generate sample renewable energy data as a fallback."""
    years = list(range(2010, 2024))
    data = {
        'ì—°ë„': years,
        'íƒœì–‘ê´‘ (TWh)': [30 + i**2.1 for i in range(len(years))],
        'í’ë ¥ (TWh)': [80 + i**2.3 for i in range(len(years))],
        'ìˆ˜ë ¥ (TWh)': [3400 + i*30 for i in range(len(years))],
    }
    df = pd.DataFrame(data)
    df_melted = df.melt(id_vars='ì—°ë„', var_name='ì—ë„ˆì§€ì›', value_name='ë°œì „ëŸ‰ (TWh)')
    return df_melted

@st.cache_data
def process_uploaded_unemployment_data(uploaded_file):
    """ì‚¬ìš©ìê°€ ì—…ë¡œë“œí•œ e-ë‚˜ë¼ì§€í‘œ ì—‘ì…€ íŒŒì¼ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
    if not uploaded_file:
        return pd.DataFrame()
    try:
        df = pd.read_excel(uploaded_file, skiprows=28, header=1)
        df = df.iloc[:, [0, 1, 3]].copy()
        df.columns = ["ì—°ë„", "ì·¨ì—…ì ìˆ˜ (ë§Œ ëª…)", "ì‹¤ì—…ë¥  (%)"]
        
        df = df.dropna(subset=["ì—°ë„"])
        df = df[pd.to_numeric(df['ì—°ë„'], errors='coerce').notna()]
        for col in df.columns:
            if col != 'ì—°ë„':
                df[col] = pd.to_numeric(df[col], errors='coerce')
        df["ì—°ë„"] = df["ì—°ë„"].astype(int)
        today = datetime.datetime.now()
        df = df[df["ì—°ë„"] < today.year]
        return df
    except Exception as e:
        st.error(f"íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}. 'openpyxl' ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì—ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return pd.DataFrame()

@st.cache_data
def load_user_employment_data():
    """ì˜ˆì‹œìš© ê¸°í›„ ì‚°ì—… ì¼ìë¦¬ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    data = {"ë…„ë„": [2017, 2018, 2019, 2020, 2021, 2022, 2023, 2024],
            "ë…¹ìƒ‰ì‚°ì—… ì¼ìë¦¬": [10.5, 11.5, 13.0, 15.0, 17.0, 19.0, 21.5, 24.0],
            "í™”ì„ì—°ë£Œ ì‚°ì—… ì¼ìë¦¬": [22.0, 21.0, 20.0, 18.0, 16.0, 14.0, 12.5, 11.0]}
    return pd.DataFrame(data)

@st.cache_data
def load_lottieurl(url: str):
    """Lottie ì• ë‹ˆë©”ì´ì…˜ ë°ì´í„° ë¡œë”© í•¨ìˆ˜ (ì¬ì‹œë„ ê¸°ëŠ¥ í¬í•¨)"""
    for _ in range(3):
        try:
            r = requests.get(url, timeout=15)
            if r.status_code == 200:
                return r.json()
        except requests.exceptions.RequestException:
            time.sleep(1)
    return None

def load_memos():
    """memos.json íŒŒì¼ì—ì„œ ëª¨ë“  ë©”ëª¨ë¥¼ ë¶ˆëŸ¬ì˜µë‹ˆë‹¤."""
    try:
        if not os.path.exists(MEMO_FILE):
            with open(MEMO_FILE, "w", encoding="utf-8") as f:
                json.dump([], f)
        with open(MEMO_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    except (FileNotFoundError, json.JSONDecodeError):
        return []

def save_memos(memos):
    """memos.json íŒŒì¼ì— ëª¨ë“  ë©”ëª¨ë¥¼ ì €ì¥í•©ë‹ˆë‹¤."""
    with open(MEMO_FILE, "w", encoding="utf-8") as f:
        json.dump(memos, f, ensure_ascii=False, indent=4)

# ==============================================================================
# 2. TAB CONTENT FUNCTIONS
# ==============================================================================
def run_survey_page():
    st.subheader("ì„¤ë¬¸ âœï¸")
    st.markdown("ì•„ë˜ **15ë¬¸í•­** ì„¤ë¬¸ì— ë‹µí•´ì£¼ì„¸ìš”!")

    q1 = st.radio("1ï¸âƒ£ ê¸°í›„ë³€í™”ê°€ ë‚´ ì§ì—…ì— ì˜í–¥ì„ ì¤„ ê²ƒ ê°™ë‚˜ìš”?", ["ì „í˜€ ì•„ë‹ˆë‹¤", "ì¡°ê¸ˆ ê·¸ë ‡ë‹¤", "ë§¤ìš° ê·¸ë ‡ë‹¤"])
    q2 = st.selectbox("2ï¸âƒ£ ê°€ì¥ ê´€ì‹¬ ìˆëŠ” ë…¹ìƒ‰ ì¼ìë¦¬ ë¶„ì•¼ëŠ”?", ["ì‹ ì¬ìƒì—ë„ˆì§€", "ESG ì»¨ì„¤íŒ…", "íƒ„ì†Œ ë°°ì¶œê¶Œ", "ê¸°í›„ ë°ì´í„° ë¶„ì„"])
    q3 = st.slider("3ï¸âƒ£ ê¸°í›„ë³€í™” ëŒ€ì‘ ì—­ëŸ‰ì„ í‚¤ìš°ê³  ì‹¶ì€ ì •ë„ (0~10)", 0, 10, 5)
    q4 = st.radio("4ï¸âƒ£ ê¸°í›„ìœ„ê¸°ë¥¼ ì–¼ë§ˆë‚˜ ì‹¬ê°í•˜ê²Œ ëŠë¼ì‹œë‚˜ìš”?", ["ì „í˜€ ì‹¬ê°í•˜ì§€ ì•Šë‹¤", "ë³´í†µì´ë‹¤", "ë§¤ìš° ì‹¬ê°í•˜ë‹¤"])
    q5 = st.checkbox("5ï¸âƒ£ ê¸°í›„ë³€í™” ëŒ€ì‘ ê´€ë ¨ êµìœ¡ì„ ë°›ì€ ì ì´ ìˆë‹¤")
    q6 = st.multiselect("6ï¸âƒ£ í‰ì†Œ ì‹¤ì²œí•˜ëŠ” ì¹œí™˜ê²½ ìƒí™œ ìŠµê´€ì„ ì„ íƒí•´ì£¼ì„¸ìš”", ["ì¬í™œìš©", "ëŒ€ì¤‘êµí†µ ì´ìš©", "ì—ë„ˆì§€ ì ˆì•½", "ì¹œí™˜ê²½ ì œí’ˆ êµ¬ë§¤", "ì±„ì‹ ì‹¤ì²œ"])
    q7 = st.radio("7ï¸âƒ£ ê¸°í›„ë³€í™” ëŒ€ì‘ì—ì„œ ë” ì¤‘ìš”í•œ ì—­í• ì„ í•´ì•¼ í•  ì£¼ì²´ëŠ” ëˆ„êµ¬ë¼ê³  ìƒê°í•˜ì‹œë‚˜ìš”?", ["ì •ë¶€", "ê¸°ì—…", "ê°œì¸", "ëª¨ë‘"])
    q8 = st.select_slider("8ï¸âƒ£ ë…¹ìƒ‰ ì „í™˜ ê³¼ì •ì—ì„œ ë‚´ ì§ì—… ì•ˆì •ì„±ì— ëŒ€í•œ ìš°ë ¤ ì •ë„", options=["ì—†ìŒ", "ë‚®ìŒ", "ë³´í†µ", "ë†’ìŒ", "ë§¤ìš° ë†’ìŒ"])
    q9 = st.text_area("9ï¸âƒ£ ë…¹ìƒ‰ ì¼ìë¦¬ í™•ëŒ€ë¥¼ ìœ„í•´ í•„ìš”í•œ ì •ì±…ì´ë‚˜ ì œì•ˆì´ ìˆë‹¤ë©´ ì ì–´ì£¼ì„¸ìš”.")
    q10 = st.radio("ğŸ”Ÿ ê¸°í›„ë³€í™” ëŒ€ì‘ì„ ìœ„í•œ ì„¸ê¸ˆ(íƒ„ì†Œì„¸ ë“±) ë¶€ê³¼ì— ë™ì˜í•˜ì‹œë‚˜ìš”?", ["ì°¬ì„±", "ë°˜ëŒ€", "ì˜ ëª¨ë¥´ê² ë‹¤"])
    q11 = st.slider("1ï¸âƒ£1ï¸âƒ£ ê¸°ì—…ì˜ ì¹œí™˜ê²½ ê²½ì˜ì´ ì¤‘ìš”í•˜ë‹¤ê³  ìƒê°í•˜ëŠ” ì •ë„ (0~10)", 0, 10, 7)
    q12 = st.radio("1ï¸âƒ£2ï¸âƒ£ ê¸°í›„ë³€í™”ë¡œ ì¸í•œ ì§ë¬´ ì¬êµìœ¡ì´ í•„ìš”í•˜ë‹¤ê³  ìƒê°í•˜ì‹œë‚˜ìš”?", ["í•„ìš” ì—†ë‹¤", "ì–´ëŠ ì •ë„ í•„ìš”í•˜ë‹¤", "ë§¤ìš° í•„ìš”í•˜ë‹¤"])
    q13 = st.multiselect("1ï¸âƒ£3ï¸âƒ£ ë…¹ìƒ‰ ì¼ìë¦¬ ì „í™˜ ì‹œ ê°€ì¥ í•„ìš”í•œ ì§€ì›ì€?", ["ì¬êµìœ¡", "ì¬ì •ì§€ì›", "ë©˜í† ë§/ìƒë‹´", "ì¼ìë¦¬ ë§¤ì¹­"])
    q14 = st.radio("1ï¸âƒ£4ï¸âƒ£ í•´ì™¸ë³´ë‹¤ êµ­ë‚´ ê¸°í›„ì •ì±…ì´ ë” ì¤‘ìš”í•˜ë‹¤ê³  ìƒê°í•˜ì‹œë‚˜ìš”?", ["êµ­ë‚´ ì •ì±…ì´ ìš°ì„ ", "í•´ì™¸ í˜‘ë ¥ì´ ë” ì¤‘ìš”", "ë‘˜ ë‹¤ ì¤‘ìš”"])
    q15 = st.text_area("1ï¸âƒ£5ï¸âƒ£ ììœ ë¡­ê²Œ ê¸°í›„ë³€í™”ì™€ ë¯¸ë˜ ì¼ìë¦¬ì— ëŒ€í•œ ì˜ê²¬ì„ ë‚¨ê²¨ì£¼ì„¸ìš”.")

    if st.button("ì„¤ë¬¸ ì œì¶œ"):
        st.success("âœ… ì„¤ë¬¸ì´ ì œì¶œë˜ì—ˆìŠµë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤!")

def run_intro_page():
    st.title("ğŸ“ ê¸°í›„ ìœ„ê¸°ëŠ” í™˜ê²½ì„ ë„˜ì–´ ì·¨ì—…ê¹Œì§€ í”ë“ ë‹¤")
    st.markdown("""
    ### ğŸŒ ê¸°í›„ ìœ„ê¸°ì™€ ì·¨ì—…, ë” ì´ìƒ ë‚¨ì˜ ì´ì•¼ê¸°ê°€ ì•„ë‹™ë‹ˆë‹¤

    ê¸°í›„ë³€í™”ëŠ” ì´ì œ 'í™˜ê²½ìš´ë™ê°€ë“¤ì˜ ì´ì•¼ê¸°'ë‚˜ 'ì§€êµ¬ ì°¨ì›ì˜ ë§‰ì—°í•œ ìœ„í˜‘'ì´ ì•„ë‹™ë‹ˆë‹¤. ì„¸ê³„ ê¸°ìƒê¸°êµ¬(WMO)ì— ë”°ë¥´ë©´ ì§€ë‚œ 10ë…„ì€ ê¸°ì˜¨ ìƒìŠ¹ í­ì´ ê°€ì¥ í° ì‹œê¸°ë¡œ ê¸°ë¡ë˜ì—ˆìœ¼ë©°, ìš°ë¦¬ë‚˜ë¼ ì—­ì‹œ í‰ê· ê¸°ì˜¨ì´ ê¾¸ì¤€íˆ ì˜¤ë¥´ê³  í­ì—¼Â·í­ìš°Â·í•œíŒŒ ê°™ì€ ê¸°í›„ì¬ë‚œì´ ë¹ˆë²ˆí•´ì§€ê³  ìˆìŠµë‹ˆë‹¤. ì¤‘ìš”í•œ ê²ƒì€ ì´ëŸ¬í•œ ë³€í™”ê°€ ë‹¨ìˆœíˆ ë‚ ì”¨ì—ë§Œ ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼, ë¯¸ë˜ì˜ ì‚°ì—… êµ¬ì¡°ì™€ ì²­ì†Œë…„ ì„¸ëŒ€ì˜ ì§„ë¡œ, ê·¸ë¦¬ê³  **ì·¨ì—…**ê¹Œì§€ ì§ì ‘ì ìœ¼ë¡œ í”ë“¤ê³  ìˆë‹¤ëŠ” ì ì…ë‹ˆë‹¤.

    ê³ ìš©ë…¸ë™ë¶€ê°€ ë°œí‘œí•œ ìë£Œì— ë”°ë¥´ë©´ **'ë…¹ìƒ‰ ì¼ìë¦¬'**ëŠ” ìµœê·¼ 5ë…„ê°„ ê¾¸ì¤€íˆ ì¦ê°€í•˜ê³  ìˆìœ¼ë©°, ì •ë¶€ëŠ” 2050 íƒ„ì†Œì¤‘ë¦½ ëª©í‘œ ë‹¬ì„±ì„ ìœ„í•´ ì‹ ì¬ìƒì—ë„ˆì§€, ì „ê¸°ì°¨, íƒ„ì†Œì €ê° ê¸°ìˆ  ê°™ì€ ë¶„ì•¼ì— ìˆ˜ì‹­ë§Œ ê°œì˜ ì‹ ê·œ ì¼ìë¦¬ë¥¼ ì°½ì¶œí•  ê³„íšì…ë‹ˆë‹¤. ë°˜ëŒ€ë¡œ, í™”ì„ì—°ë£Œ ì¤‘ì‹¬ì˜ ì „í†µ ì‚°ì—…ì€ ê¸°í›„ ê·œì œ ê°•í™”ë¡œ ì¸í•´ ì¼ìë¦¬ê°€ ì¤„ì–´ë“¤ê³  ìˆìŠµë‹ˆë‹¤.

    ê²°êµ­, ê¸°í›„ ìœ„ê¸°ëŠ” ë¯¸ë˜ ì‚¬íšŒì˜ ì·¨ì—… í™˜ê²½ì„ ê²°ì •ì§“ëŠ” í•µì‹¬ ë³€ìˆ˜ì´ë©°, ì²­ì†Œë…„ ì„¸ëŒ€ê°€ ë°˜ë“œì‹œ ì£¼ëª©í•´ì•¼ í•  ì¤‘ìš”í•œ ë¬¸ì œì„ì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    """)

def run_main_analysis_page(climate_df, co2_df, employment_df, renewable_df):
    st.title("ğŸ“ˆ ìˆ«ìê°€ ë§í•˜ëŠ” ê¸°í›„ì™€ ì¼ìë¦¬ ë³€í™”")
    st.markdown("---")

    st.markdown("""
    ### ğŸ“Š ê¸°í›„ ìœ„ê¸°, ì‹¤ì œ ë°ì´í„°ë¡œ ì¦ëª…ë©ë‹ˆë‹¤
    ê¸°í›„ ìœ„ê¸°ëŠ” ì‹¤ì œë¡œ ì‚°ì—… êµ¬ì¡°ì™€ ì·¨ì—…ë¥ ì˜ ë³€í™”ë¥¼ ë¶ˆëŸ¬ì˜¤ê³  ìˆìŠµë‹ˆë‹¤.
    
    ë¨¼ì € **í™˜ê²½ ê´€ë ¨ ì‚°ì—… ì¢…ì‚¬ì ìˆ˜**ëŠ” ê¾¸ì¤€íˆ ëŠ˜ì–´ë‚˜ëŠ” ì¶”ì„¸ì…ë‹ˆë‹¤. ê³ ìš©ë…¸ë™ë¶€ëŠ” â€˜2050 íƒ„ì†Œì¤‘ë¦½ ì‹œë‚˜ë¦¬ì˜¤â€™ë¥¼ ë°œí‘œí•˜ë©° ì¹œí™˜ê²½ ì¸í”„ë¼ êµ¬ì¶•, íƒœì–‘ê´‘Â·í’ë ¥ ë°œì „ í™•ëŒ€, ìˆ˜ì†Œ ì—ë„ˆì§€ ì‚°ì—… ìœ¡ì„±ì„ í†µí•´ ìˆ˜ì‹­ë§Œ ê°œì˜ ìƒˆë¡œìš´ ë…¹ìƒ‰ ì¼ìë¦¬ë¥¼ ì°½ì¶œí•  ê²ƒì´ë¼ê³  ë°í˜”ìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, íƒœì–‘ê´‘ íŒ¨ë„ ì„¤ì¹˜Â·ê´€ë¦¬, ì „ê¸°ì°¨ ë°°í„°ë¦¬ ê°œë°œÂ·ì¬í™œìš©, íƒ„ì†Œë°°ì¶œ ê°ì¶•ì„ ìœ„í•œ AI ê¸°ë°˜ ì‹œìŠ¤í…œ ìš´ì˜ ë“±ì€ ë¶ˆê³¼ 10ë…„ ì „ë§Œ í•´ë„ ì—†ë˜ ìƒˆë¡œìš´ ì§ì—…êµ°ì…ë‹ˆë‹¤.
    
    ë°˜ëŒ€ë¡œ **ì „í†µ ì‚°ì—…**ì€ ìœ„ê¸°ì— ì§ë©´í•´ ìˆìŠµë‹ˆë‹¤. í™”ë ¥ë°œì „ê³¼ ì„ìœ í™”í•™ ê°™ì€ ì‚°ì—…ì€ íƒ„ì†Œì„¸ì™€ í™˜ê²½ ê·œì œ ë¶€ë‹´ìœ¼ë¡œ ì¸í•´ ì ì°¨ ì¶•ì†Œë˜ê³  ìˆìœ¼ë©°, ì‹¤ì œë¡œ ì¼ë¶€ ì„íƒ„ë°œì „ì†ŒëŠ” ì¡°ê¸° íì‡„ê°€ ê²°ì •ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ ê³¼ì •ì—ì„œ í•´ë‹¹ ì—…ì¢…ì— ì¢…ì‚¬í•˜ë˜ ê·¼ë¡œìë“¤ì€ ì‹¤ì—…ì´ë‚˜ ì¬êµìœ¡ì˜ í•„ìš”ì— ì§ë©´í•˜ê³  ìˆìŠµë‹ˆë‹¤.
    
    ì•„ë˜ ëŒ€ì‹œë³´ë“œì—ì„œ ì‹¤ì œë¡œ ê¸°í›„ ê´€ë ¨ ë°ì´í„°ì™€ ì‚°ì—… ë°ì´í„°ë¥¼ ë¹„êµí•´ ë³´ì„¸ìš”.
    """)
    st.markdown("---")

    # ëŒ€ì‹œë³´ë“œ ì½”ë“œ ì‚½ì…
    st.header("ğŸ“ˆ ê³µì‹ ê³µê°œ ë°ì´í„° ê¸°ë°˜ ë¶„ì„")
    st.markdown("NASA (ê¸°ì˜¨), NOAA (COâ‚‚), World Bank (ê³ ìš©)ì˜ ê³µê°œ ë°ì´í„°ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤. API í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ ì˜ˆì‹œ ë°ì´í„°ë¡œ ìë™ ëŒ€ì²´ë©ë‹ˆë‹¤.")

    with st.container(border=True):
        st.subheader("ğŸ“Š í•µì‹¬ ì§€í‘œ ìš”ì•½", divider='rainbow')
        try:
            latest_climate = climate_df.sort_values('date', ascending=False).iloc[0]
            latest_co2 = co2_df.sort_values('date', ascending=False).iloc[0]
            col1, col2, col3 = st.columns(3)
            col1.metric(f"ìµœì‹  ì˜¨ë„ ì´ìƒì¹˜ ({latest_climate['date']:%Y-%m})", f"{latest_climate['value']:.2f} â„ƒ")
            col2.metric(f"ìµœì‹  COâ‚‚ ë†ë„ ({latest_co2['date']:%Y-%m})", f"{latest_co2['value']:.2f} ppm")
            col3.metric("ê³ ìš© ë°ì´í„° êµ­ê°€ ìˆ˜", f"{employment_df['group'].nunique()} ê°œ")
        except (IndexError, ValueError):
            st.info("í•µì‹¬ ì§€í‘œë¥¼ ê³„ì‚°í•  ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
    
    st.markdown("<br>", unsafe_allow_html=True)

    c1, c2 = st.columns(2)
    with c1:
        with st.container(border=True):
            st.subheader("ğŸŒ¡ï¸ ì§€êµ¬ í‰ê·  ì˜¨ë„ ì´ìƒì¹˜")
            show_trendline = st.checkbox("5ë…„ ì´ë™í‰ê·  ì¶”ì„¸ì„ ", value=True, key="trend_cb")
            if not climate_df.empty:
                fig = go.Figure()
                fig.add_trace(go.Scatter(x=climate_df['date'], y=climate_df['value'], mode='lines', name='ì›”ë³„ ì´ìƒì¹˜', line=dict(width=1, color='lightblue')))
                if show_trendline:
                    climate_df['trend'] = climate_df['value'].rolling(window=60, min_periods=12).mean()
                    fig.add_trace(go.Scatter(x=climate_df['date'], y=climate_df['trend'], mode='lines', name='5ë…„ ì´ë™í‰ê· ', line=dict(width=3, color='royalblue')))
                st.plotly_chart(fig, use_container_width=True)
                st.download_button("ì˜¨ë„ ë°ì´í„° ë‹¤ìš´ë¡œë“œ", climate_df.to_csv(index=False, encoding='utf-8-sig'), "climate_data.csv", "text/csv", key="dl_climate")

    with c2:
        with st.container(border=True):
            st.subheader("ğŸ’¨ ëŒ€ê¸° ì¤‘ COâ‚‚ ë†ë„")
            st.markdown("<p style='font-size: smaller;'>í•˜ì™€ì´ ë§ˆìš°ë‚˜ë¡œì•„ ê´€ì¸¡ì†Œ ê¸°ì¤€</p>", unsafe_allow_html=True)
            if not co2_df.empty:
                fig = px.line(co2_df, x='date', y='value', labels={'date': 'ë‚ ì§œ', 'value': 'COâ‚‚ (ppm)'})
                st.plotly_chart(fig, use_container_width=True)
                st.download_button("COâ‚‚ ë°ì´í„° ë‹¤ìš´ë¡œë“œ", co2_df.to_csv(index=False, encoding='utf-8-sig'), "co2_data.csv", "text/csv", key="dl_co2")

    st.markdown("<br>", unsafe_allow_html=True)

    with st.container(border=True):
        st.subheader("ğŸ­ ì‚°ì—…ë³„ ê³ ìš© ë¹„ìœ¨ ë³€í™”")
        if not employment_df.empty:
            employment_df['year'] = employment_df['date'].dt.year
            min_year = int(employment_df['year'].min())
            max_year = int(employment_df['year'].max())
            selected_year = st.slider("ì—°ë„ë¥¼ ì„ íƒí•˜ì—¬ ì§€ë„ë¥¼ ë³€ê²½í•˜ì„¸ìš”:", min_year, max_year, max_year)
            st.markdown(f"**{selected_year}ë…„ ê¸°ì¤€ ì „ ì„¸ê³„ ì‚°ì—… ê³ ìš© ë¹„ìœ¨ (Choropleth Map)**")
            map_df = employment_df[employment_df['year'] == selected_year]
            if not map_df.empty:
                fig_map = px.choropleth(map_df, locations="iso_code", color="value", hover_name="group", color_continuous_scale=px.colors.sequential.Plasma, labels={'value': 'ê³ ìš© ë¹„ìœ¨ (%)'})
                st.plotly_chart(fig_map, use_container_width=True)
            else:
                st.warning(f"{selected_year}ë…„ì—ëŠ” í‘œì‹œí•  ê³ ìš© ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

            st.markdown("**êµ­ê°€ë³„ ì‚°ì—… ê³ ìš© ë¹„ìœ¨ ì¶”ì´ ë¹„êµ**")
            all_countries = sorted(employment_df['group'].unique())
            default_countries = [c for c in ['World', 'Korea, Rep.', 'China', 'United States', 'Germany'] if c in all_countries] or all_countries[:3]
            selected_countries = st.multiselect("ë¹„êµí•  êµ­ê°€ë¥¼ ì„ íƒí•˜ì„¸ìš”:", all_countries, default=default_countries)
            if selected_countries:
                comp_df = employment_df[employment_df['group'].isin(selected_countries)]
                fig_comp = px.line(comp_df, x='year', y='value', color='group', labels={'year':'ì—°ë„', 'value':'ì‚°ì—… ê³ ìš© ë¹„ìœ¨(%)', 'group':'êµ­ê°€'})
                st.plotly_chart(fig_comp, use_container_width=True)
                st.download_button("ì„ íƒ êµ­ê°€ ê³ ìš© ë°ì´í„° ë‹¤ìš´ë¡œë“œ", comp_df.to_csv(index=False, encoding='utf-8-sig'), "employment_selected.csv", "text/csv", key="dl_emp")

    st.markdown("<br>", unsafe_allow_html=True)
    
    st.markdown("""
    ì´ëŸ¬í•œ ë°ì´í„°ëŠ” ê¸°í›„ë³€í™”ê°€ ë‹¨ìˆœíˆ í™˜ê²½ ë¬¸ì œê°€ ì•„ë‹ˆë¼, ì²­ë…„ ì„¸ëŒ€ì˜ ì¼ìë¦¬ ì§€í˜•ë„ë¥¼ ê·¼ë³¸ì ìœ¼ë¡œ ë°”ê¾¸ê³  ìˆìŒì„ ë³´ì—¬ì¤ë‹ˆë‹¤. ë¯¸ë˜ ì§„ë¡œë¥¼ ê³ ë¯¼í•˜ëŠ” í•™ìƒë“¤ì—ê²Œ ì´ëŠ” ì¤‘ìš”í•œ ì¸ì‚¬ì´íŠ¸ê°€ ë  ê²ƒì…ë‹ˆë‹¤.
    """)

def run_green_transition_page():
    st.title("ğŸ” ë…¹ìƒ‰ ì „í™˜: ìœ„í—˜ê³¼ ê¸°íšŒì˜ ë‘ ì–¼êµ´")
    st.markdown("---")

    st.markdown("""
    ### ğŸŒ¿ ë…¹ìƒ‰ ì „í™˜, ì™œ ì·¨ì—…ê³¼ ì§ê²°ë˜ëŠ”ê°€?
    í•µì‹¬ ì›ì¸ì€ ë°”ë¡œ **'ë…¹ìƒ‰ ì „í™˜(Green Transition)'**ì…ë‹ˆë‹¤. ê¸°í›„ ëŒ€ì‘ì„ ìœ„í•´ ê¸°ì—…ê³¼ ì‚¬íšŒ ì „ë°˜ì´ ì¹œí™˜ê²½ ê¸°ìˆ ì„ ë„ì…í•˜ê³ , ì´ì— ë§ëŠ” ìƒˆë¡œìš´ ì§ë¬´ë¥¼ ë§Œë“¤ì–´ë‚´ê³  ìˆê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.
    
    ì˜ˆë¥¼ ë“¤ì–´, ëŒ€ê¸°ì—…ë“¤ì€ **ESG ê²½ì˜(í™˜ê²½Â·ì‚¬íšŒÂ·ì§€ë°°êµ¬ì¡°)**ì„ ê°•í™”í•˜ë©´ì„œ í™˜ê²½ ê´€ë ¨ ì§ë¬´ ì±„ìš©ì„ í™•ëŒ€í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì‹¤ì œë¡œ ì‚¼ì„±Â·LGÂ·í˜„ëŒ€ì°¨ ê°™ì€ ëŒ€ê¸°ì—…ì€ íƒ„ì†Œë°°ì¶œ ê°ì¶•ì„ ìœ„í•œ ì „ë‹´ ë¶€ì„œë¥¼ ìš´ì˜í•˜ê³  ìˆìœ¼ë©°, ì—ë„ˆì§€Â·í™˜ê²½ ê´€ë ¨ ì „ê³µìë¥¼ ì ê·¹ì ìœ¼ë¡œ ì±„ìš©í•œë‹¤ëŠ” ì‚¬ì‹¤ì´ ì–¸ë¡ ì„ í†µí•´ ë³´ë„ëœ ë°” ìˆìŠµë‹ˆë‹¤. ì´ë¿ë§Œ ì•„ë‹ˆë¼, ê¸°í›„Â·í™˜ê²½ ìŠ¤íƒ€íŠ¸ì—…ì´ ê¸‰ê²©íˆ ì„±ì¥í•˜ë©´ì„œ ì²­ë…„ë“¤ì˜ ìƒˆë¡œìš´ ì§„ì… ê¸°íšŒê°€ ë„“ì–´ì§€ê³  ìˆìŠµë‹ˆë‹¤.
    
    ê·¸ëŸ¬ë‚˜ ê¸°í›„ ìœ„ê¸°ì˜ ë˜ ë‹¤ë¥¸ ì–¼êµ´ì€ **ìœ„í—˜**ì…ë‹ˆë‹¤. ì „í†µ ì‚°ì—…ì˜ ì¶•ì†Œì™€ ì¼ìë¦¬ ê°ì†ŒëŠ” ì²­ë…„ ì„¸ëŒ€ì—ê²Œ ì§ì ‘ì ì¸ ìœ„í˜‘ì´ ë©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ì„íƒ„ë°œì „ì†Œ ë…¸ë™ìë“¤ì´ ì§ì¥ì„ ìƒê±°ë‚˜, ìë™ì°¨ ì‚°ì—… ë‚´ ë‚´ì—°ê¸°ê´€ ì¤‘ì‹¬ ë¶€ì„œê°€ ì¶•ì†Œë˜ëŠ” í˜„ìƒì´ ì´ë¯¸ ë‚˜íƒ€ë‚˜ê³  ìˆìŠµë‹ˆë‹¤. ë”°ë¼ì„œ ê¸°í›„ ìœ„ê¸°ëŠ” ì²­ë…„ë“¤ì—ê²Œ 'ìœ„í—˜'ê³¼ 'ê¸°íšŒ'ë¥¼ ë™ì‹œì— ë˜ì ¸ì£¼ê³  ìˆìœ¼ë©°, ë³€í™”ì— ì–´ë–»ê²Œ ëŒ€ì‘í•˜ê³  ì¤€ë¹„í•˜ëŠëƒê°€ ì·¨ì—… ì„±íŒ¨ë¥¼ ì¢Œìš°í•˜ê²Œ ë©ë‹ˆë‹¤.
    
    ì´ëŸ¬í•œ ì ì—ì„œ ê¸°í›„ ìœ„ê¸°ëŠ” ë‹¨ìˆœíˆ í™˜ê²½ ìš´ë™ ì°¨ì›ì˜ ë¬¸ì œê°€ ì•„ë‹ˆë¼, **ì²­ì†Œë…„ ì§„ë¡œêµìœ¡ì˜ í•µì‹¬ ì£¼ì œ**ê°€ ë˜ì–´ì•¼ í•©ë‹ˆë‹¤. í•™êµì™€ ì‚¬íšŒê°€ í•¨ê»˜ ê¸°í›„-ì·¨ì—…ì˜ ì—°ê²°ì„±ì„ êµìœ¡í•˜ì§€ ì•ŠëŠ”ë‹¤ë©´, í•™ìƒë“¤ì€ ê¸‰ê²©íˆ ë³€í™”í•˜ëŠ” ì‚°ì—… í™˜ê²½ì— ë’¤ì²˜ì§ˆ ìˆ˜ë°–ì— ì—†ìŠµë‹ˆë‹¤.
    """)

def run_solution_page(unemployment_df, climate_raw, employment_sample_df):
    st.title("ğŸ’¡ ì²­ì†Œë…„ì´ ì¤€ë¹„í•´ì•¼ í•  ë¯¸ë˜ ì „ëµ")
    st.markdown("---")
    
    st.markdown("""
    ### ğŸš€ ê¸°í›„ ìœ„ê¸°ë¥¼ ê¸°íšŒë¡œ ë°”ê¾¸ëŠ” ì„¸ ê°€ì§€ ì œì–¸
    ì§€ê¸ˆê¹Œì§€ ì‚´í´ë³¸ ë°”ì™€ ê°™ì´, ê¸°í›„ ìœ„ê¸°ëŠ” ì§€êµ¬ í™˜ê²½ ë¬¸ì œë¥¼ ë„˜ì–´ ìš°ë¦¬ì˜ ì§„ë¡œì™€ ì·¨ì—… í™˜ê²½ì„ ì§ì ‘ì ìœ¼ë¡œ ë°”ê¾¸ê³  ìˆìŠµë‹ˆë‹¤. ê¸°í›„ ìœ„ê¸°ì— ëŒ€í•œ ì´í•´ì™€ ëŒ€ì‘ì€ ë‹¨ìˆœí•œ ì„ íƒì´ ì•„ë‹ˆë¼, ë¯¸ë˜ ì·¨ì—… ê²½ìŸë ¥ì„ ìœ„í•œ í•„ìˆ˜ ì¡°ê±´ì…ë‹ˆë‹¤.
    
    ìš°ë¦¬ëŠ” ë‹¤ìŒ ì„¸ ê°€ì§€ ì‹¤ì²œì„ ì œì•ˆí•©ë‹ˆë‹¤.
    
    **ì œì–¸ 1: ê¸°í›„ ë°ì´í„° íƒì‚¬ëŒ€ â€“ ë¯¸ë˜ ì¼ìë¦¬ íƒêµ¬í•˜ê¸°**
    ì²­ì†Œë…„ ìŠ¤ìŠ¤ë¡œ ê¸°í›„ ë°ì´í„°ì™€ ì‚°ì—… í†µê³„ë¥¼ ì°¾ì•„ ë¶„ì„í•˜ë©°, ë³€í™”í•˜ëŠ” ì·¨ì—… í™˜ê²½ì„ ì§ì ‘ íƒêµ¬í•œë‹¤.
    
    **ì œì–¸ 2: ê·¸ë¦° IT í”„ë¡œì íŠ¸ â€“ ì „ê³µê³¼ ê¸°í›„ ìœ„ê¸° ì—°ê²°í•˜ê¸°**
    ì†Œí”„íŠ¸ì›¨ì–´ê³¼ í•™ìƒì´ë¼ë©´ ê¸°í›„ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ëŠ” í”„ë¡œê·¸ë¨ì„ ë§Œë“¤ì–´ë³´ê±°ë‚˜, ì—ë„ˆì§€ ì ˆì•½ì„ ìœ„í•œ ì•± ì•„ì´ë””ì–´ë¥¼ ê¸°íší•  ìˆ˜ ìˆë‹¤.
    
    **ì œì–¸ 3: ì²­ì†Œë…„ì˜ ëª©ì†Œë¦¬ â€“ ê¸°í›„ì™€ ì·¨ì—…ì„ ì—°ê²°í•´ ì œì•ˆí•˜ê¸°**
    ê¸°í›„ ìœ„ê¸°ê°€ ê³§ ì²­ë…„ ê³ ìš© ì°½ì¶œê³¼ ì§ê²°ëœë‹¤ëŠ” ì‚¬ì‹¤ì„ ì–´ë¥¸ë“¤ì—ê²Œ ì•Œë¦¬ê³ , ì •ì±… ì œì•ˆ í™œë™ì— ì°¸ì—¬í•  ìˆ˜ ìˆë‹¤.
    """)
    st.markdown("---")

    # í•´ê²°ë°©ì•ˆ ê²Œì„ ì„¹ì…˜
    st.header("ğŸš€ í•´ê²°ë°©ì•ˆ: ë‚˜ì˜ ë¯¸ë˜ ì§ì—… ë§Œë“¤ê¸° (ê²Œì„)")
    st.info("ë‹¹ì‹ ì˜ ì„ íƒì´ ë¯¸ë˜ì˜ ì»¤ë¦¬ì–´ì™€ í™˜ê²½ì— ì–´ë–¤ ì˜í–¥ì„ ë¯¸ì¹˜ëŠ”ì§€ ì‹œë®¬ë ˆì´ì…˜ í•´ë³´ì„¸ìš”!")

    lottie_study = load_lottieurl("https://lottie.host/175b5a27-63f5-4220-8374-e32a13f789e9/5N7sBfSbB6.json")
    lottie_activity = load_lottieurl("https://lottie.host/97217a14-a957-41a4-9e1e-2879685a21e0/p3T5exs27n.json")
    lottie_career = load_lottieurl("https://lottie.host/7e05e830-7456-4c31-b844-93b5a1b55909/Rk4yQO6fS3.json")

    st.subheader("1ï¸âƒ£ ë‹¹ì‹ ì˜ ì„ íƒì€?")
    col1, col2, col3 = st.columns(3)
    with col1:
        if lottie_study: st_lottie(lottie_study, height=150, key="study")
        st.markdown("#### í•™ì—… í™œë™")
        edu_choice = st.radio("ì–´ë–¤ ê³¼ëª©ì— ë” ì§‘ì¤‘í• ê¹Œìš”?", ('íƒ„ì†Œ ë°°ì¶œëŸ‰ ë¶„ì„ AI ëª¨ë¸ë§', 'ì „í†µ ë‚´ì—°ê¸°ê´€ íš¨ìœ¨ì„± ì—°êµ¬'), key="edu")
    with col2:
        if lottie_activity: st_lottie(lottie_activity, height=150, key="activity")
        st.markdown("#### ëŒ€ì™¸ í™œë™")
        activity_choice = st.radio("ì–´ë–¤ ë™ì•„ë¦¬ì— ê°€ì…í• ê¹Œìš”?", ('ì‹ ì¬ìƒì—ë„ˆì§€ ì •ì±… í† ë¡  ë™ì•„ë¦¬', 'ê³ ì „ ë¬¸í•™ ë¹„í‰ ë™ì•„ë¦¬'), key="activity")
    with col3:
        if lottie_career: st_lottie(lottie_career, height=150, key="career")
        st.markdown("#### ì§„ë¡œ íƒìƒ‰")
        career_choice = st.radio("ì–´ë–¤ ê¸°ì—…ì˜ ì¸í„´ì‹­ì— ì§€ì›í• ê¹Œìš”?", ('ì—ë„ˆì§€ IT ìŠ¤íƒ€íŠ¸ì—…', 'ì•ˆì •ì ì¸ ì •ìœ íšŒì‚¬'), key="career")

    base_score = 50; base_co2 = 0; skills = []
    if edu_choice == 'íƒ„ì†Œ ë°°ì¶œëŸ‰ ë¶„ì„ AI ëª¨ë¸ë§':
        score_edu = 25; co2_edu = -15; skills.extend(["AI/ë¨¸ì‹ ëŸ¬ë‹", "ë°ì´í„° ë¶„ì„"])
    else:
        score_edu = 5; co2_edu = 5; skills.append("ê¸°ê³„ ê³µí•™")
    if activity_choice == 'ì‹ ì¬ìƒì—ë„ˆì§€ ì •ì±… í† ë¡  ë™ì•„ë¦¬':
        score_activity = 15; co2_activity = -10; skills.extend(["ì •ì±… ì´í•´", "í† ë¡  ë° ì„¤ë“"])
    else:
        score_activity = 5; co2_activity = 0; skills.append("ì¸ë¬¸í•™ì  ì†Œì–‘")
    if career_choice == 'ì—ë„ˆì§€ IT ìŠ¤íƒ€íŠ¸ì—…':
        score_career = 20; co2_career = -10; skills.extend(["ì‹¤ë¬´ ê²½í—˜", "ë¬¸ì œ í•´ê²° ëŠ¥ë ¥"])
    else:
        score_career = 10; co2_career = 5; skills.append("ëŒ€ê¸°ì—… í”„ë¡œì„¸ìŠ¤ ì´í•´")
    final_score = round(base_score + score_edu + score_activity + score_career)
    final_co2 = round(base_co2 + co2_edu + co2_activity + co2_career)
    final_skills = list(set(skills))

    st.subheader("2ï¸âƒ£ 10ë…„ í›„, ë‹¹ì‹ ì˜ ëª¨ìŠµì€?")
    st.markdown(f"""
    <div style="background-color: #F0F2F6; border-radius: 10px; padding: 20px; display: flex; justify-content: space-around; align-items: center; color: black;">
        <div style="text-align: center;">
            <span style="font-size: 1.2em;">ğŸ“ ë¯¸ë˜ ì»¤ë¦¬ì–´ ê²½ìŸë ¥</span><br>
            <span style="font-size: 2.5em; font-weight: bold;">{final_score}</span><span style="font-size: 1.5em;"> ì </span>
        </div>
        <div style="text-align: center;">
            <span style="font-size: 1.2em;">ğŸŒ± í™˜ê²½ ê¸°ì—¬ë„ (COâ‚‚)</span><br>
            <span style="font-size: 2.5em; font-weight: bold;">{-final_co2}</span><span style="font-size: 1.5em;"> ê°ì¶•</span>
        </div>
        <div style="text-align: center;">
            <span style="font-size: 1.2em;">ğŸ”‘ íšë“í•œ í•µì‹¬ ì—­ëŸ‰</span><br>
            <span style="font-size: 1.2em;">{', '.join(final_skills) if final_skills else 'ì„ íƒ ëŒ€ê¸°ì¤‘...'}</span>
        </div>
    </div>
    """, unsafe_allow_html=True)
    st.markdown("<br>", unsafe_allow_html=True)
    if final_score >= 100:
        st.success("ğŸ‰ **ì™„ë²½í•œ ë¯¸ë˜ ì¸ì¬!** ë‹¹ì‹ ì€ ê¸°í›„ ìœ„ê¸°ë¥¼ ê¸°íšŒë¡œ ë§Œë“œëŠ” ì‹œëŒ€ì˜ ë¦¬ë”ê°€ ë  ê²ƒì…ë‹ˆë‹¤.", icon="ğŸš€")
    elif final_score >= 75:
        st.info("ğŸ‘ **ìœ ë§í•œ ì¸ì¬!** ë…¹ìƒ‰ ì „í™˜ ì‹œëŒ€ì— ì„±ê³µì ìœ¼ë¡œ ì ì‘í•  ìˆ˜ ìˆëŠ” ë›°ì–´ë‚œ ì ì¬ë ¥ì„ ê°–ì·„ìŠµë‹ˆë‹¤.", icon="ğŸŒŸ")
    else:
        st.warning("ğŸ¤” **ì„±ì¥ ê°€ëŠ¥ì„±!** ë³€í™”í•˜ëŠ” ì‚°ì—… íŠ¸ë Œë“œì— ì¡°ê¸ˆ ë” ê´€ì‹¬ì„ ê°€ì§„ë‹¤ë©´ ë‹¹ì‹ ì˜ ë¯¸ë˜ëŠ” ë”ìš± ë°ì•„ì§ˆ ê±°ì˜ˆìš”.", icon="ğŸ’¡")

    st.markdown("---")
    
    # ë‚˜ì˜ ì‹¤ì²œ ë‹¤ì§ ë‚¨ê¸°ê¸° (ê³µìœ  ë°©ëª…ë¡)
    st.header("âœï¸ ë‚˜ì˜ ì‹¤ì²œ ë‹¤ì§ ë‚¨ê¸°ê¸° (ê³µìœ  ë°©ëª…ë¡)")
    st.write("ì—¬ëŸ¬ë¶„ì˜ ë‹¤ì§ì€ ì´ ì›¹ì‚¬ì´íŠ¸ì— ì˜êµ¬ì ìœ¼ë¡œ ì €ì¥ë˜ì–´ ëª¨ë“  ë°©ë¬¸ìì—ê²Œ ê³µìœ ë©ë‹ˆë‹¤!")
    
    cols = st.columns([0.7, 0.3])
    with cols[0]:
        name = st.text_input("ë‹‰ë„¤ì„", placeholder="ìì‹ ì„ í‘œí˜„í•˜ëŠ” ë©‹ì§„ ë‹‰ë„¤ì„ì„ ì ì–´ì£¼ì„¸ìš”!", key="memo_name")
        memo = st.text_area("ì‹¤ì²œ ë‹¤ì§", placeholder="ì˜ˆ) í…€ë¸”ëŸ¬ ì‚¬ìš©í•˜ê¸°, ê°€ê¹Œìš´ ê±°ë¦¬ëŠ” ê±¸ì–´ë‹¤ë‹ˆê¸° ë“±", key="memo_text")
    with cols[1]:
        color = st.color_picker("ë©”ëª¨ì§€ ìƒ‰ìƒ ì„ íƒ", "#FFFACD", key="memo_color")
        if st.button("ë‹¤ì§ ë‚¨ê¸°ê¸°!", use_container_width=True):
            if name and memo:
                all_memos = load_memos()
                all_memos.insert(0, {"name": name, "memo": memo, "color": color, "timestamp": str(datetime.datetime.now())})
                save_memos(all_memos)
                st.balloons()
                st.success("ì†Œì¤‘í•œ ë‹¤ì§ì´ ëª¨ë‘ì—ê²Œ ê³µìœ ë˜ì—ˆìŠµë‹ˆë‹¤!")
                st.rerun()
            else:
                st.warning("ë‹‰ë„¤ì„ê³¼ ë‹¤ì§ì„ ëª¨ë‘ ì…ë ¥í•´ì£¼ì„¸ìš”!")
    
    st.divider()
    st.subheader("ğŸ’¬ ìš°ë¦¬ì˜ ë‹¤ì§ë“¤")
    memos_list = load_memos()
    
    if not memos_list:
        st.info("ì•„ì§ ì‘ì„±ëœ ë‹¤ì§ì´ ì—†ì–´ìš”. ì²« ë²ˆì§¸ ë‹¤ì§ì„ ë‚¨ê²¨ì£¼ì„¸ìš”!")
    else:
        memo_cols = st.columns(3)
        for i, m in enumerate(memos_list):
            with memo_cols[i % 3]:
                st.markdown(f"""
                <div style="background-color:{m.get('color', '#FFFACD')}; border-left: 5px solid #FF6347; border-radius: 8px; padding: 15px; margin-bottom: 20px; box-shadow: 0 4px 8px rgba(0,0,0,0.1); height: 150px;">
                    <p style="font-size: 1.1em; color: black; margin-bottom: 10px;">"{m.get('memo', '')}"</p>
                    <strong style="font-size: 0.9em; color: #555;">- {m.get('name', '')} -</strong>
                </div>
                """, unsafe_allow_html=True)
    
    st.markdown("---")
    
    st.subheader("ğŸŒ ì°¸ê³  ìë£Œ")
    st.markdown("""
    * ëŒ€í•™ì§„í•™ë¥  ë° ì·¨ì—…ë¥  ê·¸ë˜í”„, ì—¬ì„±ê°€ì¡±ë¶€, [https://www.ypec.re.kr/mps/youthStat/education/collegeEmployRate?menuId=MENU00757](https://www.ypec.re.kr/mps/youthStat/education/collegeEmployRate?menuId=MENU00757)
    * ê¸°í›„ë³€í™” 4ëŒ€ì§€í‘œ, íƒ„ì†Œì¤‘ë¦½ ì •ì±…í¬í„¸, [https://www.gihoo.or.kr/statistics.es?mid=a30401000000](https://www.gihoo.or.kr/statistics.es?mid=a30401000000)
    * í–¥í›„ 10ë…„ ì‚¬ë¼ì§ˆ ì§ì—… 1ìœ„ëŠ”?, í¬ì¼“ë‰´ìŠ¤ ë‹¤ìŒì±„ë„, [https://v.daum.net/v/4z6QWe3IKx](https://v.daum.net/v/4z6QWe3IKx)
    * ì£¼ìš” ì—…ì¢… ì¼ìë¦¬ ê·¸ë˜í”„, ê³ ìš©ë…¸ë™ë¶€, [https://www.moel.go.kr/news/enews/report/enewsView.do?news_seq=17516](https://www.moel.go.kr/news/enews/report/enewsView.do?news_seq=17516)
    * **ì¶”ê°€ ì¶œì²˜**: NASA GISTEMP, NOAA GML, World Bank
    """)

# ==============================================================================
# 3. MAIN APPLICATION LOGIC
# ==============================================================================
def main():
    """Main function to run the Streamlit app."""
    # --- Data Loading and Session State Management ---
    if 'data_loaded' not in st.session_state:
        # **[ìˆ˜ì •]** fetch_gistemp_csv()ê°€ ë¹ˆ DataFrameì„ ë°˜í™˜í•  ê²½ìš°ë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì²˜ë¦¬
        climate_data = fetch_gistemp_csv()
        if climate_data.empty:
            st.session_state.climate_df = preprocess_dataframe(get_sample_climate_data())
        else:
            st.session_state.climate_df = preprocess_dataframe(climate_data)
            
        # **[ìˆ˜ì •]** co2 ë°ì´í„° ì²˜ë¦¬
        co2_data = fetch_noaa_co2_data()
        if co2_data.empty:
            st.session_state.co2_df = preprocess_dataframe(get_sample_co2_data())
        else:
            st.session_state.co2_df = preprocess_dataframe(co2_data)

        # **[ìˆ˜ì •]** ê³ ìš© ë°ì´í„° ì²˜ë¦¬
        employment_data = fetch_worldbank_employment()
        if employment_data.empty:
            st.session_state.employment_df = preprocess_dataframe(get_sample_employment_data())
        else:
            st.session_state.employment_df = preprocess_dataframe(employment_data)
            
        st.session_state.renewable_df = get_sample_renewable_data()
        st.session_state.uploaded_unemployment_df = pd.DataFrame()
        st.session_state.data_loaded = True

    # --- Sidebar for Navigation and Upload ---
    with st.sidebar:
        st.header("ğŸ“Š ì˜µì…˜ ì„¤ì •")
        uploaded_file = st.file_uploader("ì·¨ì—…ë¥  ì—‘ì…€ íŒŒì¼ ì—…ë¡œë“œ", type=["xlsx", "xls"])
        if uploaded_file:
            st.session_state.uploaded_unemployment_df = process_uploaded_unemployment_data(uploaded_file)
        
        all_years = pd.concat([
            st.session_state.uploaded_unemployment_df['ì—°ë„'] if not st.session_state.uploaded_unemployment_df.empty else pd.Series(dtype='int'),
            pd.Series(st.session_state.climate_df['date'].dt.year.unique(), dtype='int')
        ]).dropna().unique()

        min_year, max_year = (int(all_years.min()), int(all_years.max())) if len(all_years) > 0 else (2017, datetime.datetime.now().year - 1)
        year_range = st.slider("í‘œì‹œí•  ì—°ë„ ë²”ìœ„", min_year, max_year, (min_year, max_year))
        
        st.header("ğŸ“– ëª©ì°¨")
        st.markdown("""
        - [ğŸ“ ì„œë¡ ](#-ê¸°í›„-ìœ„ê¸°ì™€-ì·¨ì—…-ë”-ì´ìƒ-ë‚¨ì˜-ì´ì•¼ê¸°ê°€-ì•„ë‹™ë‹ˆë‹¤)
        - [ğŸ“ˆ ë³¸ë¡  1](#-ê¸°í›„-ìœ„ê¸°-ì‹¤ì œ-ë°ì´í„°ë¡œ-ì¦ëª…ë©ë‹ˆë‹¤)
        - [ğŸ” ë³¸ë¡  2](#-ë…¹ìƒ‰-ì „í™˜-ì™œ-ì·¨ì—…ê³¼-ì§ê²°ë˜ëŠ”ê°€)
        - [ğŸ’¡ ê²°ë¡  ë° ì œì–¸](#-ê¸°í›„-ìœ„ê¸°ë¥¼-ê¸°íšŒë¡œ-ë°”ê¾¸ëŠ”-ì„¸-ê°€ì§€-ì œì–¸)
        - [ğŸš€ ê²Œì„](#-í•´ê²°ë°©ì•ˆ-ë‚˜ì˜-ë¯¸ë˜-ì§ì—…-ë§Œë“¤ê¸°-ê²Œì„)
        - [âœï¸ ë°©ëª…ë¡](#-ë‚˜ì˜-ì‹¤ì²œ-ë‹¤ì§-ë‚¨ê¸°ê¸°-ê³µìœ -ë°©ëª…ë¡)
        """)

    # --- Main Page Content ---
    st.markdown("<h1 style='text-align: center;'>ğŸŒ ê¸°í›„ ìœ„ê¸°ëŠ” í™˜ê²½ì„ ë„˜ì–´ ì·¨ì—…ê¹Œì§€ í”ë“ ë‹¤</h1>", unsafe_allow_html=True)
    st.markdown("<p style='text-align: center; font-size: 1.2em; font-weight: bold;'>1403 ê¶Œì´ˆí˜„, 1405 ê¹€ë™í˜„, 1410 ì‹ ìˆ˜ì•„, 1416 ì¡°ì •ëª¨</p>", unsafe_allow_html=True)

    tab1, tab2, tab3, tab4, tab5 = st.tabs(["ğŸ“Š ì„¤ë¬¸ì¡°ì‚¬", "ğŸ“ ì„œë¡ ", "ğŸ“ˆ ë³¸ë¡  1", "ğŸ” ë³¸ë¡  2", "ğŸ’¡ ê²°ë¡  ë° ì œì–¸"])

    with tab1:
        run_survey_page()

    with tab2:
        run_intro_page()

    with tab3:
        run_main_analysis_page(st.session_state.climate_df, st.session_state.co2_df, st.session_state.employment_df, st.session_state.renewable_df)

    with tab4:
        run_green_transition_page()

    with tab5:
        run_solution_page(st.session_state.uploaded_unemployment_df, st.session_state.climate_df, load_user_employment_data())

if __name__ == "__main__":
    main()